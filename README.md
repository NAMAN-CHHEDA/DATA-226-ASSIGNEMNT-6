# DATA-226-ASSIGNEMNT-6
# ðŸ“Š Weekly Active User (WAU) Analysis

## ðŸ“˜ Overview
This project implements an end-to-end data pipeline and analytics workflow using **Apache Airflow**, **Snowflake**, and a **Business Intelligence (BI)** tool.  
The objective is to generate and visualize the **Weekly Active User (WAU)** metric from session data through ETL, ELT, and dashboard creation processes.

---

## ðŸ§© Tasks Performed

### 1. ETL DAG Creation (Airflow)
- Imported two tables into **Snowflake**:
  - `user_session_channel`
  - `session_timestamp`
- Designed an **ETL DAG** in **Apache Airflow** to load the above tables under the `raw` schema (or an equivalent schema).
- Captured a screenshot of the DAGâ€™s detailed page from the **Airflow Web UI**.  
  ðŸ“· *Screenshot #1 â€” ETL DAG*

---

### 2. ELT DAG Creation (Airflow)
- Developed an **ELT DAG** in **Apache Airflow** to join the two imported tables and create a new table named `session_summary` under the `analytics` schema.
- Added an **additional condition** to check for duplicate records in the data pipeline.
- Captured a screenshot of the DAGâ€™s detailed page from the **Airflow Web UI**.  
  ðŸ“· *Screenshot #2 â€” ELT DAG*

---

### 3. Preset Account Setup
- Configured a **Preset** account and established a **Snowflake connection**.
- Imported the `session_summary` table generated from the ELT DAG.
- Captured a screenshot of the dataset view in **Preset**.  
  ðŸ“· *Screenshot #3 â€” Dataset View*

---

### 4. WAU Chart Creation (BI Tool)
- Created a **Weekly Active User (WAU)** chart using the BI tool (Preset/Tableau/Power BI).
- Renamed the metric field to **WAU** for clarity.
- Captured a screenshot of the final WAU visualization.  
  ðŸ“· *Screenshot #4 â€” WAU Chart*

---

## ðŸ“‚ Repository Structure
```text
â”œâ”€â”€ dags/
â”‚ â”œâ”€â”€ etl_user_session_dag.py
â”‚ â”œâ”€â”€ elt_session_summary_dag.py
â”œâ”€â”€ screenshots/
â”‚ â”œâ”€â”€ airflow_etl_dag.png
â”‚ â”œâ”€â”€ airflow_elt_dag.png
â”‚ â”œâ”€â”€ preset_dataset.png
â”‚ â”œâ”€â”€ wau_chart.png
â”œâ”€â”€ README.md
```

---

## ðŸ’¡ Notes
- This assignment demonstrates the workflow of **data extraction, transformation, and visualization** using **Airflow**, **Snowflake**, and **Preset**.
- All screenshots are stored in the `screenshots/` folder.
- All DAG scripts (`ETL` and `ELT`) are stored under the `dags/` directory.
- The WAU chart reflects aggregated user activity data over weekly intervals.

---

## ðŸ§  Learning Outcomes
- Gained practical experience with **ETL/ELT pipelines** in Airflow.
- Understood data integration with **Snowflake**.
- Created **interactive dashboards** using a BI tool.
- Applied data validation techniques to ensure data quality.
